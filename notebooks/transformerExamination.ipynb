{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936b9abd-47f8-455f-b22d-a0aaece57cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from PIL import Image\n",
    "root_dir = '../'\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "# ViT-CLTT\n",
    "from models.vit_contrastive import Backbone, ViTConfigExtended, ViTConfig, configuration, LitClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3538de-f40c-46d6-b21d-a810165dec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT AND LOAD MODEL\n",
    "def init_model(model, model_path=None, heads=3, patch_size=8, image_size=64):\n",
    "    if model == 'vit':\n",
    "        configuration = ViTConfigExtended()\n",
    "        configuration.patch_size = patch_size\n",
    "        configuration.image_size = image_size\n",
    "        backbone = Backbone(model_type=\"vit\", config=configuration)\n",
    "        model = LitClassifier(backbone=backbone).load_from_checkpoint(model_path).backbone\n",
    "        model.fc = nn.Identity()\n",
    "    elif model == 'untrained_vit':\n",
    "        configuration = ViTConfigExtended()\n",
    "        configuration.num_attention_heads = configuration.num_hidden_layers = heads\n",
    "        configuration.patch_size = patch_size\n",
    "        configuration.image_size = image_size\n",
    "        # print configuration parameters of ViT\n",
    "        print('image_size - ', configuration.image_size)\n",
    "        print('patch_size - ', configuration.patch_size)\n",
    "        print('num_classes - ', configuration.num_classes)\n",
    "        print('hidden_size - ', configuration.hidden_size)\n",
    "        print('intermediate_size - ', configuration.intermediate_size)\n",
    "        print('num_hidden_layers - ', configuration.num_hidden_layers)\n",
    "        print('num_attention_heads - ', configuration.num_attention_heads)\n",
    "        \n",
    "        # pass the configuration parameters to get backbone\n",
    "        backbone = Backbone('vit', configuration)\n",
    "        model = LitClassifier(backbone).backbone\n",
    "        model.fc = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0085d38f-7b13-4b26-9489-57245eb738ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define the color you want to use\n",
    "my_color = 'red' #        ->10\n",
    "my_color2 = 'blue' #      ->50\n",
    "my_color3 = 'black' #     ->90\n",
    "my_color4 = 'green'#      ->40\n",
    "my_color5 = 'grey'\n",
    "my_color6 = 'deeppink' #\n",
    "my_color7 = 'orange' #    ->20\n",
    "my_color8 = 'pink' #      ->0Â°\n",
    "my_color9 = 'yellow' #    ->30 \n",
    "my_color10 = 'brown' #    ->80\n",
    "my_color11 = 'purple' #   ->70\n",
    "my_color12 = 'navy' #     ->60\n",
    "\n",
    "# Create a custom colormap with only one color\n",
    "cmap_self = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color, my_color])\n",
    "cmap_self2 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color2, my_color2])\n",
    "cmap_self3 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color3, my_color3])\n",
    "cmap_self4 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color4, my_color4])\n",
    "cmap_self5 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color5, my_color5])\n",
    "cmap_self6 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color6, my_color6])\n",
    "cmap_self7 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color7, my_color7])\n",
    "cmap_self8 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color8, my_color8])\n",
    "cmap_self9 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color9, my_color9])\n",
    "cmap_self10 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color10, my_color10])\n",
    "cmap_self11 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color11, my_color11])\n",
    "cmap_self12 = mcolors.LinearSegmentedColormap.from_list(\"\", [my_color12, my_color12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd2170f-b5c0-4ad4-87ae-06071d262e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model successfully loaded.\n",
      "[INFO] All 2000 image paths loaded successfully!\n",
      "[INFO] Layers selected -- \n",
      " ['model.model.transformer.layers.1.1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "During the forward pass, whenever the model processes an image, \n",
    "the registered hook captures the output of that layer.\n",
    "for example - \n",
    "layer.register_forward_hook(hook_fn)\n",
    "\n",
    "When you register a hook, PyTorch returns a handle \n",
    "(handle = layer.register_forward_hook(hook_fn)). \n",
    "This handle is an object that keeps track of the registered hook.\n",
    "If you don't remove the hook, it persists in the model, and future\n",
    "forward passes will keep executing the hook, possibly \n",
    "causing memory issues or unintended behavior.\n",
    "\n",
    "'''\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "def get_intermediate_outputs(model, image_paths, layer_names):\n",
    "    \"\"\"Extracts outputs from specified layers of a frozen PyTorch model.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    intermediate_outputs = {name: [] for name in layer_names}\n",
    "    device = next(model.parameters()).device  # Get model device\n",
    "\n",
    "    \n",
    "    def hook_fn(module, input, output, layer_name):\n",
    "        # check and do average pooling of intermediate layers \n",
    "        if output.dim()>2: # this is an intermediate layer\n",
    "            # remove the extra token i.e., the cls token - \n",
    "            output = output[:, 1:, :]\n",
    "            # average mean of the patch dims -\n",
    "            output = output.mean(dim=1) # you can also try max pooling here!\n",
    "            \n",
    "        intermediate_outputs[layer_name].append(output.detach().cpu())\n",
    "\n",
    "    handles = []\n",
    "    for name in layer_names:\n",
    "        try:\n",
    "            layer = model\n",
    "            for part in name.split('.'):\n",
    "                layer = getattr(layer, part) # basically we reach the layer that we want the ouput from!\n",
    "            handle = layer.register_forward_hook(lambda module, input, output, layer_name=name: hook_fn(module, input, output, layer_name))\n",
    "            handles.append(handle)\n",
    "        except AttributeError:\n",
    "            print(f\"Layer '{name}' not found in the model.\")\n",
    "            return {}\n",
    "    \n",
    "    transform = T.Compose([\n",
    "        T.Resize((64,64)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "    image_labels = []\n",
    "    with torch.no_grad():\n",
    "        for image_path in image_paths:\n",
    "            img = Image.open(image_path)\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            model(img_tensor)  # Hooks capture outputs here\n",
    "\n",
    "            # Extract the parent directory as the label\n",
    "            label = os.path.basename(os.path.dirname(image_path))\n",
    "            image_labels.append(label)\n",
    "\n",
    "    # Remove hooks after processing all images\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "\n",
    "    return intermediate_outputs, image_labels\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Load model \n",
    "ckpt = \"/data/lpandey/LOGS/VIT_Time/NeurIPS2025_RW_Rebuttal/temporallyScrambedlwithScheduler/vit6h/version_0/checkpoints/epoch=99-step=118799.ckpt\"\n",
    "model_type = \"vit\"\n",
    "model = init_model(model=model_type, model_path=ckpt, heads=3, patch_size=8, image_size=64)\n",
    "\n",
    "print(\"[INFO] Model successfully loaded.\")\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# store all the test images in a list and select layers -  \n",
    "image_paths = []\n",
    "root_dir = \"/data/lpandey/KittenAI_Dataset/LinearProbeTrainTest/test\"\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        image_paths.append(file_path)\n",
    "\n",
    "print(\"[INFO] All {} image paths loaded successfully!\".format(len(image_paths)))\n",
    "\n",
    "# print(\"[INFO] Model Layers -- \")\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n",
    "\n",
    "# enter layer names from which you want the outputs from here -\n",
    "layer_names = [\"model.model.transformer.layers.1.1\"] # model.model.mlp_head, model.model.transformer.layers.0.1, model.model.transformer.layers.1.1, model.model.transformer.layers.2.1\n",
    "\n",
    "if not layer_names:\n",
    "    raise ValueError(\"No layer names provided. Please specify the layers to extract.\")\n",
    "\n",
    "print(\"[INFO] Layers selected -- \\n\", layer_names)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# Call function - \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device) \n",
    "model.eval()\n",
    "\n",
    "\n",
    "intermediate_outputs, image_labels = get_intermediate_outputs(model, image_paths, layer_names)\n",
    "\n",
    "# if intermediate_outputs:\n",
    "#     for layer_name, outputs in intermediate_outputs.items():\n",
    "#         print(f\"Outputs from layer '{layer_name}':\")\n",
    "#         for output in outputs:\n",
    "#             print(output.shape)\n",
    "# else:\n",
    "#     print(\"Failed to get intermediate outputs.\")\n",
    "\n",
    "# print(image_labels)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "# plot tSNE - \n",
    "# Flatten all feature vectors for t-SNE\n",
    "layer_name = layer_names[0]  # Assuming only one layer is used\n",
    "features = np.vstack(intermediate_outputs[layer_name])  # Convert to (num_samples, feature_dim) , ex - [2000, 512]\n",
    "\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "tsne_results = tsne.fit_transform(features)  # Shape (num_samples, 2)\n",
    "\n",
    "# Assign unique colors to each directory\n",
    "\n",
    "unique_labels = sorted(list(set(image_labels))) # [0,10,20,...,90]\n",
    "\n",
    "#label_to_color = {label: plt.cm.jet(i / len(unique_labels)) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "label_to_color = {\n",
    "    '0': cmap_self8(0),\n",
    "    '10': cmap_self(1),\n",
    "    '20': cmap_self7(2),\n",
    "    '30': cmap_self9(3),\n",
    "    '40': cmap_self4(4),\n",
    "    '50': cmap_self2(5),\n",
    "    '60': cmap_self12(6),\n",
    "    '70': cmap_self11(7),\n",
    "    '80': cmap_self10(8),\n",
    "    '90': cmap_self3(9),\n",
    "}\n",
    "\n",
    "colors = [label_to_color[label] for label in image_labels]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot the t-SNE results\n",
    "# plt.figure(figsize=(10, 7))\n",
    "for i, label in enumerate(unique_labels):\n",
    "    indices = [j for j, lbl in enumerate(image_labels) if lbl == label]\n",
    "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], color=label_to_color[label], label=label, alpha=0.7)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title(\"t-SNE Visualization of Extracted Features\")\n",
    "# plt.xlabel(\"t-SNE Dimension 1\")\n",
    "# plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142e485-7856-4168-93d9-4a2db52eb159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea56ce33-578e-4858-9c48-e7ecceb7c386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc7b2d-fc8b-4201-b703-d1fd2cd99f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277579d8-f44a-4200-976d-9722fadd50f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
